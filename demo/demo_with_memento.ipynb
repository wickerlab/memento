{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Demonstration -- A machine learning pipeline with Memento\n",
    "\n",
    "The benefit of using Memento:\n",
    "\n",
    "- Avoiding all the copy and paste when running repeated experiments;\n",
    "- Experiments are running in parallel.\n",
    "- Focusing on the workflow of one experiment;\n",
    "- Keep all configurations in one place;\n",
    "- Using checkpoints to keep tracking progress;\n",
    "- Send notification when the experiments fail or finish;\n",
    "\n",
    "To start this project:\n",
    "\n",
    "```bash\n",
    "# Using Python 3.9.x (Memento support Python 3.7, 3.8 and 3.9)\n",
    "conda create -n memento python=3.9\n",
    "conda activate memento\n",
    "\n",
    "# Install dependencies\n",
    "pip install memento-ml scikit-learn jupyterlab\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import logging\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import (FunctionTransformer, MinMaxScaler,\n",
    "                                   StandardScaler)\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from memento import Config, ConsoleNotificationProvider, Context, Memento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_missing_values(X, missing_rate=0.1):\n",
    "    \"\"\"Add missing features to n percent of samples. Remove 1 feature per sample.\"\"\"\n",
    "    n_samples, n_features = X.shape\n",
    "    n_missing_samples = int(n_samples * missing_rate)\n",
    "\n",
    "    idx_missing_samples = np.random.choice(n_samples, size=n_missing_samples, replace=True)\n",
    "    idx_missing_features = np.random.randint(0, n_features, n_missing_samples)\n",
    "    \n",
    "    X_missing = X.copy()\n",
    "    X_missing[idx_missing_samples, idx_missing_features] = np.nan\n",
    "    return X_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A dummy preprocessing class which returns X unchanged.\n",
    "DummyPreprocessor = FunctionTransformer(lambda x: x)\n",
    "\n",
    "# Using `partial` to avoid passing parameter in the experiment function.\n",
    "load_digits = functools.partial(datasets.load_digits, return_X_y=True)\n",
    "load_wine = functools.partial(datasets.load_wine, return_X_y=True)\n",
    "def load_breast_cancer():\n",
    "    \"\"\"Add missing values to Breast Cancer dataset.\"\"\"\n",
    "    X, y = datasets.load_breast_cancer(return_X_y=True)\n",
    "    X_missing = add_missing_values(X, missing_rate=0.1)\n",
    "    return X_missing, y\n",
    "\n",
    "Imputer = SimpleImputer(missing_values=np.nan, strategy=\"mean\")\n",
    "\n",
    "# Put all parameters in a configuration matrix\n",
    "matrix = {\n",
    "    \"parameters\": {\n",
    "        \"dataset\": [\n",
    "            load_digits,\n",
    "            load_wine,\n",
    "            load_breast_cancer,\n",
    "        ],\n",
    "        \"preprocessing1\": [\n",
    "            DummyPreprocessor,\n",
    "            Imputer,\n",
    "        ],\n",
    "        \"preprocessing2\": [\n",
    "            DummyPreprocessor,\n",
    "            MinMaxScaler(),\n",
    "            StandardScaler(),\n",
    "        ],\n",
    "        \"classifier\": [\n",
    "            AdaBoostClassifier,\n",
    "            RandomForestClassifier,\n",
    "            SVC,\n",
    "        ],\n",
    "    },\n",
    "    \"settings\": { # Set global values here\n",
    "        \"n_fold\": 5,\n",
    "    },\n",
    "    \"exclude\": [\n",
    "        {\"dataset\": load_breast_cancer, \"preprocessing1\": DummyPreprocessor},\n",
    "        {\"dataset\": load_digits, \"preprocessing1\": Imputer},\n",
    "        {\"dataset\": load_wine, \"preprocessing1\": Imputer},\n",
    "    ]\n",
    "}\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `experiment` function is the building block for **Memento**. \n",
    "It takes two parameters: `Context` and `Config`.\n",
    "Memento will automatically figure out how many tasks it need to create based on the configuration matrix, and execute them in parallel. \n",
    "Each task will execute this `experiment` function but with different parameters (inside `Config`).\n",
    "\n",
    "- The `Context` exposes a handler, so the user can access `checkpoint` in the `experiment` function.\n",
    "- The `Config` provides one set of parameter (from the configuration matrix) to the experiment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment(context: Context, config: Config):\n",
    "    \"\"\"This block contains the experiment with one set of parameters.\n",
    "    \"\"\"\n",
    "    X, y = config.dataset()\n",
    "    clf = config.classifier()\n",
    "\n",
    "    pipeline = make_pipeline(config.preprocessing1, config.preprocessing2, clf)\n",
    "    cv = config.settings[\"n_fold\"]\n",
    "\n",
    "    if context.checkpoint_exist():\n",
    "        scores = context.restore()\n",
    "    else:\n",
    "        scores = cross_val_score(pipeline, X, y, cv=cv)\n",
    "        context.checkpoint(scores)\n",
    "    return scores.mean() * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:memento.memento:Running configurations:\n",
      "INFO:memento.memento:  {'dataset': functools.partial(<function load_digits at 0x0000015495312310>, return_X_y=True), 'preprocessing1': FunctionTransformer(func=<function <lambda> at 0x00000154B5A6D670>), 'preprocessing2': FunctionTransformer(func=<function <lambda> at 0x00000154B5A6D670>), 'classifier': <class 'sklearn.ensemble._weight_boosting.AdaBoostClassifier'>}\n",
      "INFO:memento.memento:  {'dataset': functools.partial(<function load_digits at 0x0000015495312310>, return_X_y=True), 'preprocessing1': FunctionTransformer(func=<function <lambda> at 0x00000154B5A6D670>), 'preprocessing2': FunctionTransformer(func=<function <lambda> at 0x00000154B5A6D670>), 'classifier': <class 'sklearn.ensemble._forest.RandomForestClassifier'>}\n",
      "INFO:memento.memento:  {'dataset': functools.partial(<function load_digits at 0x0000015495312310>, return_X_y=True), 'preprocessing1': FunctionTransformer(func=<function <lambda> at 0x00000154B5A6D670>), 'preprocessing2': FunctionTransformer(func=<function <lambda> at 0x00000154B5A6D670>), 'classifier': <class 'sklearn.svm._classes.SVC'>}\n",
      "INFO:memento.memento:  {'dataset': functools.partial(<function load_digits at 0x0000015495312310>, return_X_y=True), 'preprocessing1': FunctionTransformer(func=<function <lambda> at 0x00000154B5A6D670>), 'preprocessing2': MinMaxScaler(), 'classifier': <class 'sklearn.ensemble._weight_boosting.AdaBoostClassifier'>}\n",
      "INFO:memento.memento:  {'dataset': functools.partial(<function load_digits at 0x0000015495312310>, return_X_y=True), 'preprocessing1': FunctionTransformer(func=<function <lambda> at 0x00000154B5A6D670>), 'preprocessing2': MinMaxScaler(), 'classifier': <class 'sklearn.ensemble._forest.RandomForestClassifier'>}\n",
      "INFO:memento.memento:  {'dataset': functools.partial(<function load_digits at 0x0000015495312310>, return_X_y=True), 'preprocessing1': FunctionTransformer(func=<function <lambda> at 0x00000154B5A6D670>), 'preprocessing2': MinMaxScaler(), 'classifier': <class 'sklearn.svm._classes.SVC'>}\n",
      "INFO:memento.memento:  {'dataset': functools.partial(<function load_digits at 0x0000015495312310>, return_X_y=True), 'preprocessing1': FunctionTransformer(func=<function <lambda> at 0x00000154B5A6D670>), 'preprocessing2': StandardScaler(), 'classifier': <class 'sklearn.ensemble._weight_boosting.AdaBoostClassifier'>}\n",
      "INFO:memento.memento:  {'dataset': functools.partial(<function load_digits at 0x0000015495312310>, return_X_y=True), 'preprocessing1': FunctionTransformer(func=<function <lambda> at 0x00000154B5A6D670>), 'preprocessing2': StandardScaler(), 'classifier': <class 'sklearn.ensemble._forest.RandomForestClassifier'>}\n",
      "INFO:memento.memento:  {'dataset': functools.partial(<function load_digits at 0x0000015495312310>, return_X_y=True), 'preprocessing1': FunctionTransformer(func=<function <lambda> at 0x00000154B5A6D670>), 'preprocessing2': StandardScaler(), 'classifier': <class 'sklearn.svm._classes.SVC'>}\n",
      "INFO:memento.memento:  {'dataset': functools.partial(<function load_wine at 0x0000015495312160>, return_X_y=True), 'preprocessing1': FunctionTransformer(func=<function <lambda> at 0x00000154B5A6D670>), 'preprocessing2': FunctionTransformer(func=<function <lambda> at 0x00000154B5A6D670>), 'classifier': <class 'sklearn.ensemble._weight_boosting.AdaBoostClassifier'>}\n",
      "INFO:memento.memento:  {'dataset': functools.partial(<function load_wine at 0x0000015495312160>, return_X_y=True), 'preprocessing1': FunctionTransformer(func=<function <lambda> at 0x00000154B5A6D670>), 'preprocessing2': FunctionTransformer(func=<function <lambda> at 0x00000154B5A6D670>), 'classifier': <class 'sklearn.ensemble._forest.RandomForestClassifier'>}\n",
      "INFO:memento.memento:  {'dataset': functools.partial(<function load_wine at 0x0000015495312160>, return_X_y=True), 'preprocessing1': FunctionTransformer(func=<function <lambda> at 0x00000154B5A6D670>), 'preprocessing2': FunctionTransformer(func=<function <lambda> at 0x00000154B5A6D670>), 'classifier': <class 'sklearn.svm._classes.SVC'>}\n",
      "INFO:memento.memento:  {'dataset': functools.partial(<function load_wine at 0x0000015495312160>, return_X_y=True), 'preprocessing1': FunctionTransformer(func=<function <lambda> at 0x00000154B5A6D670>), 'preprocessing2': MinMaxScaler(), 'classifier': <class 'sklearn.ensemble._weight_boosting.AdaBoostClassifier'>}\n",
      "INFO:memento.memento:  {'dataset': functools.partial(<function load_wine at 0x0000015495312160>, return_X_y=True), 'preprocessing1': FunctionTransformer(func=<function <lambda> at 0x00000154B5A6D670>), 'preprocessing2': MinMaxScaler(), 'classifier': <class 'sklearn.ensemble._forest.RandomForestClassifier'>}\n",
      "INFO:memento.memento:  {'dataset': functools.partial(<function load_wine at 0x0000015495312160>, return_X_y=True), 'preprocessing1': FunctionTransformer(func=<function <lambda> at 0x00000154B5A6D670>), 'preprocessing2': MinMaxScaler(), 'classifier': <class 'sklearn.svm._classes.SVC'>}\n",
      "INFO:memento.memento:  {'dataset': functools.partial(<function load_wine at 0x0000015495312160>, return_X_y=True), 'preprocessing1': FunctionTransformer(func=<function <lambda> at 0x00000154B5A6D670>), 'preprocessing2': StandardScaler(), 'classifier': <class 'sklearn.ensemble._weight_boosting.AdaBoostClassifier'>}\n",
      "INFO:memento.memento:  {'dataset': functools.partial(<function load_wine at 0x0000015495312160>, return_X_y=True), 'preprocessing1': FunctionTransformer(func=<function <lambda> at 0x00000154B5A6D670>), 'preprocessing2': StandardScaler(), 'classifier': <class 'sklearn.ensemble._forest.RandomForestClassifier'>}\n",
      "INFO:memento.memento:  {'dataset': functools.partial(<function load_wine at 0x0000015495312160>, return_X_y=True), 'preprocessing1': FunctionTransformer(func=<function <lambda> at 0x00000154B5A6D670>), 'preprocessing2': StandardScaler(), 'classifier': <class 'sklearn.svm._classes.SVC'>}\n",
      "INFO:memento.memento:  {'dataset': <function load_breast_cancer at 0x00000154B5A6D940>, 'preprocessing1': SimpleImputer(), 'preprocessing2': FunctionTransformer(func=<function <lambda> at 0x00000154B5A6D670>), 'classifier': <class 'sklearn.ensemble._weight_boosting.AdaBoostClassifier'>}\n",
      "INFO:memento.memento:  {'dataset': <function load_breast_cancer at 0x00000154B5A6D940>, 'preprocessing1': SimpleImputer(), 'preprocessing2': FunctionTransformer(func=<function <lambda> at 0x00000154B5A6D670>), 'classifier': <class 'sklearn.ensemble._forest.RandomForestClassifier'>}\n",
      "INFO:memento.memento:  {'dataset': <function load_breast_cancer at 0x00000154B5A6D940>, 'preprocessing1': SimpleImputer(), 'preprocessing2': FunctionTransformer(func=<function <lambda> at 0x00000154B5A6D670>), 'classifier': <class 'sklearn.svm._classes.SVC'>}\n",
      "INFO:memento.memento:  {'dataset': <function load_breast_cancer at 0x00000154B5A6D940>, 'preprocessing1': SimpleImputer(), 'preprocessing2': MinMaxScaler(), 'classifier': <class 'sklearn.ensemble._weight_boosting.AdaBoostClassifier'>}\n",
      "INFO:memento.memento:  {'dataset': <function load_breast_cancer at 0x00000154B5A6D940>, 'preprocessing1': SimpleImputer(), 'preprocessing2': MinMaxScaler(), 'classifier': <class 'sklearn.ensemble._forest.RandomForestClassifier'>}\n",
      "INFO:memento.memento:  {'dataset': <function load_breast_cancer at 0x00000154B5A6D940>, 'preprocessing1': SimpleImputer(), 'preprocessing2': MinMaxScaler(), 'classifier': <class 'sklearn.svm._classes.SVC'>}\n",
      "INFO:memento.memento:  {'dataset': <function load_breast_cancer at 0x00000154B5A6D940>, 'preprocessing1': SimpleImputer(), 'preprocessing2': StandardScaler(), 'classifier': <class 'sklearn.ensemble._weight_boosting.AdaBoostClassifier'>}\n",
      "INFO:memento.memento:  {'dataset': <function load_breast_cancer at 0x00000154B5A6D940>, 'preprocessing1': SimpleImputer(), 'preprocessing2': StandardScaler(), 'classifier': <class 'sklearn.ensemble._forest.RandomForestClassifier'>}\n",
      "INFO:memento.memento:  {'dataset': <function load_breast_cancer at 0x00000154B5A6D940>, 'preprocessing1': SimpleImputer(), 'preprocessing2': StandardScaler(), 'classifier': <class 'sklearn.svm._classes.SVC'>}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tasks completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:memento.memento:0/27 results retrieved from cache\n"
     ]
    }
   ],
   "source": [
    "notification_provider = ConsoleNotificationProvider()\n",
    "results = Memento(experiment, notification_provider).run(matrix)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we rerun the cell above, since there is no parameter changes and all results have been save the in the cache, the code will complete instantly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[26.765552460538533,\n",
       " 93.7143299288146,\n",
       " 96.32838130609717,\n",
       " 26.765552460538533,\n",
       " 93.60229031259672,\n",
       " 95.9942742185082,\n",
       " 26.765552460538533,\n",
       " 94.2700402352213,\n",
       " 94.60229031259672,\n",
       " 80.84126984126983,\n",
       " 96.09523809523809,\n",
       " 66.34920634920634,\n",
       " 80.28571428571428,\n",
       " 97.20634920634922,\n",
       " 97.76190476190477,\n",
       " 80.28571428571428,\n",
       " 97.2063492063492,\n",
       " 98.33333333333334,\n",
       " 97.19142990218911,\n",
       " 95.786368576308,\n",
       " 90.86632510479738,\n",
       " 97.1914299021891,\n",
       " 95.78481602235678,\n",
       " 97.54075454122031,\n",
       " 96.66200900481292,\n",
       " 95.43238627542307,\n",
       " 97.53920198726907]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show avg. accuracy in percentage (Note that we multiple 100 in the experiment block)\n",
    "[result.inner for result in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[datetime.timedelta(seconds=1, microseconds=28007),\n",
       " datetime.timedelta(seconds=1, microseconds=345212),\n",
       " datetime.timedelta(microseconds=430004),\n",
       " datetime.timedelta(seconds=1, microseconds=49011),\n",
       " datetime.timedelta(seconds=1, microseconds=430011),\n",
       " datetime.timedelta(microseconds=421003),\n",
       " datetime.timedelta(seconds=1, microseconds=146010),\n",
       " datetime.timedelta(seconds=1, microseconds=312587),\n",
       " datetime.timedelta(microseconds=560004),\n",
       " datetime.timedelta(microseconds=401004),\n",
       " datetime.timedelta(microseconds=798006),\n",
       " datetime.timedelta(microseconds=38999),\n",
       " datetime.timedelta(microseconds=389002),\n",
       " datetime.timedelta(microseconds=671003),\n",
       " datetime.timedelta(microseconds=27999),\n",
       " datetime.timedelta(microseconds=406001),\n",
       " datetime.timedelta(microseconds=720004),\n",
       " datetime.timedelta(microseconds=27002),\n",
       " datetime.timedelta(microseconds=901006),\n",
       " datetime.timedelta(microseconds=866002),\n",
       " datetime.timedelta(microseconds=63000),\n",
       " datetime.timedelta(microseconds=735005),\n",
       " datetime.timedelta(seconds=1, microseconds=133008),\n",
       " datetime.timedelta(microseconds=62001),\n",
       " datetime.timedelta(microseconds=761008),\n",
       " datetime.timedelta(seconds=1, microseconds=154010),\n",
       " datetime.timedelta(microseconds=92999)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show experiment\"s runtime \n",
    "[result.runtime for result in results]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Streamline parameter tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = {\n",
    "    \"parameters\": {\n",
    "        \"dataset\": [\n",
    "            functools.partial(datasets.load_breast_cancer, return_X_y=True),\n",
    "        ],\n",
    "        \"preprocessing\": [\n",
    "            StandardScaler(),\n",
    "        ],\n",
    "        \"classifier\": [\n",
    "            SVC,\n",
    "        ],\n",
    "        \"svm_C\": [1, 10, 100, 1000],\n",
    "        \"svm_gamma\": [0.001, 0.0001]\n",
    "    },\n",
    "    \"settings\": { # Set global values here\n",
    "        \"n_fold\": 5,\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment(context: Context, config: Config):\n",
    "    X, y = config.dataset()\n",
    "    svm_C = config.svm_C\n",
    "    svm_gamma = config.svm_gamma\n",
    "    clf = config.classifier(C=svm_C, gamma=svm_gamma)\n",
    "    pipeline = make_pipeline(config.preprocessing, clf)\n",
    "    cv = config.settings[\"n_fold\"]\n",
    "\n",
    "    if context.checkpoint_exist():\n",
    "        scores = context.restore()\n",
    "    else:\n",
    "        scores = cross_val_score(pipeline, X, y, cv=cv)\n",
    "        context.checkpoint(scores)\n",
    "    return scores.mean() * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:memento.memento:Running configurations:\n",
      "INFO:memento.memento:  {'dataset': functools.partial(<function load_breast_cancer at 0x0000015495312280>, return_X_y=True), 'preprocessing': StandardScaler(), 'classifier': <class 'sklearn.svm._classes.SVC'>, 'svm_C': 1, 'svm_gamma': 0.001}\n",
      "INFO:memento.memento:  {'dataset': functools.partial(<function load_breast_cancer at 0x0000015495312280>, return_X_y=True), 'preprocessing': StandardScaler(), 'classifier': <class 'sklearn.svm._classes.SVC'>, 'svm_C': 1, 'svm_gamma': 0.0001}\n",
      "INFO:memento.memento:  {'dataset': functools.partial(<function load_breast_cancer at 0x0000015495312280>, return_X_y=True), 'preprocessing': StandardScaler(), 'classifier': <class 'sklearn.svm._classes.SVC'>, 'svm_C': 10, 'svm_gamma': 0.001}\n",
      "INFO:memento.memento:  {'dataset': functools.partial(<function load_breast_cancer at 0x0000015495312280>, return_X_y=True), 'preprocessing': StandardScaler(), 'classifier': <class 'sklearn.svm._classes.SVC'>, 'svm_C': 10, 'svm_gamma': 0.0001}\n",
      "INFO:memento.memento:  {'dataset': functools.partial(<function load_breast_cancer at 0x0000015495312280>, return_X_y=True), 'preprocessing': StandardScaler(), 'classifier': <class 'sklearn.svm._classes.SVC'>, 'svm_C': 100, 'svm_gamma': 0.001}\n",
      "INFO:memento.memento:  {'dataset': functools.partial(<function load_breast_cancer at 0x0000015495312280>, return_X_y=True), 'preprocessing': StandardScaler(), 'classifier': <class 'sklearn.svm._classes.SVC'>, 'svm_C': 100, 'svm_gamma': 0.0001}\n",
      "INFO:memento.memento:  {'dataset': functools.partial(<function load_breast_cancer at 0x0000015495312280>, return_X_y=True), 'preprocessing': StandardScaler(), 'classifier': <class 'sklearn.svm._classes.SVC'>, 'svm_C': 1000, 'svm_gamma': 0.001}\n",
      "INFO:memento.memento:  {'dataset': functools.partial(<function load_breast_cancer at 0x0000015495312280>, return_X_y=True), 'preprocessing': StandardScaler(), 'classifier': <class 'sklearn.svm._classes.SVC'>, 'svm_C': 1000, 'svm_gamma': 0.0001}\n",
      "INFO:memento.memento:0/8 results retrieved from cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tasks completed\n"
     ]
    }
   ],
   "source": [
    "notification_provider = ConsoleNotificationProvider()\n",
    "results = Memento(experiment, notification_provider).run(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[94.73063188945815,\n",
       " 79.62272938984628,\n",
       " 97.01443875174661,\n",
       " 94.73063188945815,\n",
       " 97.01443875174661,\n",
       " 97.18987734823784,\n",
       " 97.36686849868033,\n",
       " 97.18987734823784]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[result.inner for result in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "e8a14c2cb3206237cd982c8447566eef72ed9b8a95eca3109a9df28d87592576"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demonstration -- A standard machine learning pipeline without Memento\n",
    "\n",
    "- The same virtual environment can be used as in `demo_with_memento.ipynb`.\n",
    "\n",
    "To start this project:\n",
    "\n",
    "```bash\n",
    "# Using Python 3.9.x (Memento support Python 3.7, 3.8 and 3.9)\n",
    "conda create -n memento python=3.9\n",
    "conda activate memento\n",
    "\n",
    "# Install dependencies\n",
    "pip install memento-ml scikit-learn jupyterlab\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import (FunctionTransformer, MinMaxScaler,\n",
    "                                   StandardScaler)\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_missing_values(X, missing_rate=0.1):\n",
    "    \"\"\"Add missing features to n percent of samples. Remove 1 feature per sample.\"\"\"\n",
    "    n_samples, n_features = X.shape\n",
    "    n_missing_samples = int(n_samples * missing_rate)\n",
    "\n",
    "    idx_missing_samples = np.random.choice(\n",
    "        n_samples, size=n_missing_samples, replace=True\n",
    "    )\n",
    "    idx_missing_features = np.random.randint(0, n_features, n_missing_samples)\n",
    "\n",
    "    X_missing = X.copy()\n",
    "    X_missing[idx_missing_samples, idx_missing_features] = np.nan\n",
    "    return X_missing\n",
    "\n",
    "def load_breast_cancer():\n",
    "    \"\"\"Add missing values to Breast Cancer dataset.\"\"\"\n",
    "    X, y = datasets.load_breast_cancer(return_X_y=True)\n",
    "    X_missing = add_missing_values(X, missing_rate=0.1)\n",
    "    return X_missing, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits_x, digits_y = datasets.load_digits(return_X_y=True)\n",
    "wine_x, wine_y = datasets.load_wine(return_X_y=True)\n",
    "breast_x, breast_y = load_breast_cancer()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark 2 preprocessing methods and 3 classifiers\n",
    "\n",
    "- `make_pipeline` is used to ensure `scaler` is applied after splitting.\n",
    "- To make the code as short as possible, we use `cross_val_score` which calls `StratifiedKFold` internally by default.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_FOLD = 5\n",
    "\n",
    "def run_dataset(X, y, with_missing_val=False):\n",
    "    \"\"\"Given a dataset, benchmark 2 preprocessing methods and 3 classifiers\n",
    "    Preprocessing methods:\n",
    "    1. No preprocessing\n",
    "    2. Apply MinMax scaler (Rescale features to 0-1)\n",
    "    3. Apply Standard scaler (0 mean, 1 standard deviation)\n",
    "\n",
    "    Classifiers:\n",
    "    1. AdaBoost\n",
    "    2. RandomForest\n",
    "    3. SVM\n",
    "    \"\"\"\n",
    "    if with_missing_val:\n",
    "        Imputer = SimpleImputer(missing_values=np.nan, strategy=\"mean\")\n",
    "    else:\n",
    "        # A dummy preprocessing class which returns X unchanged.\n",
    "        Imputer = FunctionTransformer(lambda x: x)\n",
    "\n",
    "    # No preprocessing step\n",
    "    pipeline_ada = make_pipeline(Imputer, AdaBoostClassifier())\n",
    "    pipeline_rf = make_pipeline(Imputer, RandomForestClassifier())\n",
    "    pipeline_svm = make_pipeline(Imputer, SVC())\n",
    "\n",
    "    # With MinMax scaler\n",
    "    pipeline_minmax_ada = make_pipeline(Imputer, MinMaxScaler(), AdaBoostClassifier())\n",
    "    pipeline_minmax_rf = make_pipeline(Imputer, MinMaxScaler(), RandomForestClassifier())\n",
    "    pipeline_minmax_svm = make_pipeline(Imputer, MinMaxScaler(), SVC())\n",
    "\n",
    "    # With Standard scaler\n",
    "    pipeline_std_ada = make_pipeline(Imputer, StandardScaler(), AdaBoostClassifier())\n",
    "    pipeline_std_rf = make_pipeline(Imputer, StandardScaler(), RandomForestClassifier())\n",
    "    pipeline_std_svm = make_pipeline(Imputer, StandardScaler(), SVC())\n",
    "\n",
    "    scores = []\n",
    "    avg_score = cross_val_score(pipeline_ada, X, y, cv=NUM_FOLD)\n",
    "    scores.append((\"None-AdaBoost\", np.mean(avg_score)))\n",
    "    avg_score = cross_val_score(pipeline_rf, X, y, cv=NUM_FOLD)\n",
    "    scores.append((\"None-RandomForest\", np.mean(avg_score)))\n",
    "    avg_score = cross_val_score(pipeline_svm, X, y, cv=NUM_FOLD)\n",
    "    scores.append((\"None-SVM\", np.mean(avg_score)))\n",
    "\n",
    "    avg_score = cross_val_score(pipeline_minmax_ada, X, y, cv=NUM_FOLD)\n",
    "    scores.append((\"MinMax-AdaBoost\", np.mean(avg_score)))\n",
    "    avg_score = cross_val_score(pipeline_minmax_rf, X, y, cv=NUM_FOLD)\n",
    "    scores.append((\"MinMax-RandomForest\", np.mean(avg_score)))\n",
    "    avg_score = cross_val_score(pipeline_minmax_svm, X, y, cv=NUM_FOLD)\n",
    "    scores.append((\"MinMax-SVM\", np.mean(avg_score)))\n",
    "\n",
    "    avg_score = cross_val_score(pipeline_std_ada, X, y, cv=NUM_FOLD)\n",
    "    scores.append((\"STD-AdaBoost\", np.mean(avg_score)))\n",
    "    avg_score = cross_val_score(pipeline_std_rf, X, y, cv=NUM_FOLD)\n",
    "    scores.append((\"STD-RandomForest\", np.mean(avg_score)))\n",
    "    avg_score = cross_val_score(pipeline_std_svm, X, y, cv=NUM_FOLD)\n",
    "    scores.append((\"STD-SVM\", np.mean(avg_score)))\n",
    "    return scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Digits ===\n",
      "[None-AdaBoost       ] Avg. score: 26.77%\n",
      "[None-RandomForest   ] Avg. score: 93.10%\n",
      "[None-SVM            ] Avg. score: 96.33%\n",
      "[MinMax-AdaBoost     ] Avg. score: 26.71%\n",
      "[MinMax-RandomForest ] Avg. score: 93.32%\n",
      "[MinMax-SVM          ] Avg. score: 95.99%\n",
      "[STD-AdaBoost        ] Avg. score: 26.77%\n",
      "[STD-RandomForest    ] Avg. score: 93.94%\n",
      "[STD-SVM             ] Avg. score: 94.60%\n",
      "\n",
      "=== Wine ===\n",
      "[None-AdaBoost       ] Avg. score: 80.84%\n",
      "[None-RandomForest   ] Avg. score: 96.65%\n",
      "[None-SVM            ] Avg. score: 66.35%\n",
      "[MinMax-AdaBoost     ] Avg. score: 80.29%\n",
      "[MinMax-RandomForest ] Avg. score: 97.76%\n",
      "[MinMax-SVM          ] Avg. score: 97.76%\n",
      "[STD-AdaBoost        ] Avg. score: 80.29%\n",
      "[STD-RandomForest    ] Avg. score: 96.10%\n",
      "[STD-SVM             ] Avg. score: 98.33%\n",
      "\n",
      "=== Breast Cancer ===\n",
      "[None-AdaBoost       ] Avg. score: 96.84%\n",
      "[None-RandomForest   ] Avg. score: 95.78%\n",
      "[None-SVM            ] Avg. score: 91.22%\n",
      "[MinMax-AdaBoost     ] Avg. score: 96.66%\n",
      "[MinMax-RandomForest ] Avg. score: 96.49%\n",
      "[MinMax-SVM          ] Avg. score: 97.54%\n",
      "[STD-AdaBoost        ] Avg. score: 96.84%\n",
      "[STD-RandomForest    ] Avg. score: 96.14%\n",
      "[STD-SVM             ] Avg. score: 97.54%\n"
     ]
    }
   ],
   "source": [
    "scores = run_dataset(digits_x, digits_y)\n",
    "print(\"=== Digits ===\")\n",
    "for name, score in scores:\n",
    "    print(\"[{:20s}] Avg. score: {:.2f}%\".format(name, score * 100))\n",
    "\n",
    "scores = run_dataset(wine_x, wine_y)\n",
    "print(\"\\n=== Wine ===\")\n",
    "for name, score in scores:\n",
    "    print(\"[{:20s}] Avg. score: {:.2f}%\".format(name, score * 100))\n",
    "\n",
    "scores = run_dataset(breast_x, breast_y, with_missing_val=True)\n",
    "print(\"\\n=== Breast Cancer ===\")\n",
    "for name, score in scores:\n",
    "    print(\"[{:20s}] Avg. score: {:.2f}%\".format(name, score * 100))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e8a14c2cb3206237cd982c8447566eef72ed9b8a95eca3109a9df28d87592576"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
